{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from imageio import imwrite\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.5-introduction-to-gans.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Convolution GAN - DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура сети:\n",
    "* Сеть generator отображает векторы с формой (размерность_скрытого_простаранства) в изображения с формой (32, 32, 3).\n",
    "Размерность изображения соответсвует размерам образцов из датасета CIFAR10\n",
    "* Сеть discriminator отображает изображения с формой (32, 32, 3) в оценку вероятности того, что изображение является настоящим.\n",
    "* Сеть gan объединяет генератор и дискриминатор gan(x) = discriminator(generator(x)). То есть сеть отображает скрытое простарнство векторов в оценку их реализма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дискриминатор будет обучен на изображениях с метками настоящее\\поддельное. <br>\n",
    "Для обучения генератора мы используем градиенты весов в отношении потерь модели gan. То есть на каждом шаге мы будем смещать веса генератора в направлении увеличения вероятности классификации изображений, декодированных как \"настоящие\". <br>\n",
    "Проще говоря, будем учить генератор обманывать дискриминатор, повышая качество сгенерированных изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Генератор** <br>\n",
    "Преобразует вектор из срытого пространства в изображение - кандидат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Grigoriy\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Grigoriy\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Grigoriy\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "generator_input = keras.Input(shape = (latent_dim,))\n",
    "\n",
    "# Преобразование входа в карту признаков 16х16 со 128 каналами\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "# Увеличиваем разрешение с 16х16 до 32х32\n",
    "x = layers.Conv2D(256, 5, padding = 'same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(256, 4, strides = 2, padding = 'same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding = 'same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding = 'same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(channels, 7, activation = 'tanh', padding = 'same')(x)\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дискриминатор**<br>\n",
    "Принимает изображение-кандидат и относит его к одному из двух классов: \"подделка\" или \"настоящее\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Grigoriy\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Grigoriy\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Grigoriy\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Grigoriy\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Grigoriy\\.conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = layers.Input(shape = (height, width, channels))\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides = 2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides = 2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides = 2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(lr = 0.0008, \n",
    "                                                   clipvalue = 1.0, # градиентная обрезка (клиппинг)\n",
    "                                                   decay = 1e-8) # затухание скорости обучения, для стабилизации\n",
    "discriminator.compile(optimizer = discriminator_optimizer, \n",
    "                     loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Состязательная сеть**<br>\n",
    "Объединятет генератор и дискриминатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False #Заморозка весов дискриминатора\n",
    "\n",
    "gan_input = keras.Input(shape = (latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr = 0.0004, clipvalue = 1.0, decay = 1e-8)\n",
    "gan.compile(optimizer = gan_optimizer, loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузка данных и обучение**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train[y_train.flatten() == 2] # Выбираем класс изображений \"птицы\"\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0],) + (height, width, channels)).astype('float32')/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цикл обучения:\n",
    "* Извлечь случайные точки (случайный шум) из скрытого пространства.\n",
    "* Создать изображение из генератора, использовав эти точки.\n",
    "* Смешать сгенерированные изображения с настоящими.\n",
    "* Обучить дискриминатор на этом наборе изображений, добавив к нему соответсвующие метки: \"настоящее\"/\"подделка\".\n",
    "* Выбрать новые точки из сркытого пространства.\n",
    "* Обучить gan, использовав эти случайные изображения, присвоив им метки \"настоящее\". Так как внутри gan веса дискриминатора заморожены, то в процессе обучения сместяться только веса генератора, в направлении получения от дискриминатора ответа \"настоящее\". Это научит генератор обманывать дискриминатор.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a384445fc0fb4b1a8d01f1d1432d075c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grigoriy\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss 0.6994667\n",
      "adversarial loss 0.69242454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grigoriy\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss 0.6087915\n",
      "adversarial loss 1.1073045\n",
      "discriminator loss 0.71135503\n",
      "adversarial loss 0.7715578\n",
      "discriminator loss 0.68249387\n",
      "adversarial loss 0.781381\n",
      "discriminator loss 0.70685387\n",
      "adversarial loss 0.74431384\n",
      "discriminator loss 0.7259246\n",
      "adversarial loss 0.80166066\n",
      "discriminator loss 0.70093817\n",
      "adversarial loss 0.7494663\n",
      "discriminator loss 0.70459735\n",
      "adversarial loss 0.74912757\n",
      "discriminator loss 0.6764239\n",
      "adversarial loss 1.1373749\n",
      "discriminator loss 0.686679\n",
      "adversarial loss 0.73525727\n",
      "discriminator loss 0.7045886\n",
      "adversarial loss 0.7429808\n",
      "discriminator loss 0.69294196\n",
      "adversarial loss 0.7489681\n",
      "discriminator loss 0.7333188\n",
      "adversarial loss 0.74504364\n",
      "discriminator loss 0.69226444\n",
      "adversarial loss 0.7433859\n",
      "discriminator loss 0.69779664\n",
      "adversarial loss 0.7492\n",
      "discriminator loss 0.69904435\n",
      "adversarial loss 0.74151397\n",
      "discriminator loss 0.69340587\n",
      "adversarial loss 0.7503307\n",
      "discriminator loss 0.71144533\n",
      "adversarial loss 0.78564095\n",
      "discriminator loss 0.69222486\n",
      "adversarial loss 0.7636314\n",
      "discriminator loss 0.6985351\n",
      "adversarial loss 0.75298786\n",
      "discriminator loss 0.69958997\n",
      "adversarial loss 0.7792853\n",
      "discriminator loss 0.6908048\n",
      "adversarial loss 0.7521269\n",
      "discriminator loss 0.70188445\n",
      "adversarial loss 0.77953005\n",
      "discriminator loss 0.70394915\n",
      "adversarial loss 0.743878\n",
      "discriminator loss 0.7179794\n",
      "adversarial loss 0.72541606\n",
      "discriminator loss 0.69409454\n",
      "adversarial loss 0.6923965\n",
      "discriminator loss 0.6937608\n",
      "adversarial loss 0.80022794\n",
      "discriminator loss 0.68787926\n",
      "adversarial loss 0.7428405\n",
      "discriminator loss 0.70029926\n",
      "adversarial loss 0.76304525\n",
      "discriminator loss 0.68511057\n",
      "adversarial loss 0.7891544\n",
      "discriminator loss 0.6995581\n",
      "adversarial loss 0.7290317\n",
      "discriminator loss 0.69508314\n",
      "adversarial loss 0.74992347\n",
      "discriminator loss 0.6915425\n",
      "adversarial loss 0.77358055\n",
      "discriminator loss 0.7048299\n",
      "adversarial loss 0.7368812\n",
      "discriminator loss 0.6883291\n",
      "adversarial loss 0.74805045\n",
      "discriminator loss 0.7078379\n",
      "adversarial loss 0.7571377\n",
      "discriminator loss 0.6827431\n",
      "adversarial loss 0.75198495\n",
      "discriminator loss 0.7226656\n",
      "adversarial loss 0.76334935\n",
      "discriminator loss 0.6838552\n",
      "adversarial loss 0.78798896\n",
      "discriminator loss 0.7155323\n",
      "adversarial loss 0.80886555\n",
      "discriminator loss 0.6991147\n",
      "adversarial loss 0.74437207\n",
      "discriminator loss 0.6995675\n",
      "adversarial loss 0.7401106\n",
      "discriminator loss 0.7390728\n",
      "adversarial loss 0.69979876\n",
      "discriminator loss 0.69264\n",
      "adversarial loss 0.7863904\n",
      "discriminator loss 0.6927827\n",
      "adversarial loss 0.76945573\n",
      "discriminator loss 0.6964948\n",
      "adversarial loss 0.7520094\n",
      "discriminator loss 0.692629\n",
      "adversarial loss 0.7248758\n",
      "discriminator loss 0.709197\n",
      "adversarial loss 0.7413414\n",
      "discriminator loss 0.69058543\n",
      "adversarial loss 0.7468482\n",
      "discriminator loss 0.6834443\n",
      "adversarial loss 0.7676417\n",
      "discriminator loss 0.78616065\n",
      "adversarial loss 0.7349194\n",
      "discriminator loss 0.6769335\n",
      "adversarial loss 0.67481434\n",
      "discriminator loss 0.6991566\n",
      "adversarial loss 0.7508264\n",
      "discriminator loss 0.69859314\n",
      "adversarial loss 0.7366564\n",
      "discriminator loss 0.6926364\n",
      "adversarial loss 0.76045525\n",
      "discriminator loss 0.69730216\n",
      "adversarial loss 0.72950804\n",
      "discriminator loss 0.6894045\n",
      "adversarial loss 0.7339895\n",
      "discriminator loss 0.7032764\n",
      "adversarial loss 0.7396416\n",
      "discriminator loss 0.6978984\n",
      "adversarial loss 0.7629839\n",
      "discriminator loss 0.6837367\n",
      "adversarial loss 0.85983884\n",
      "discriminator loss 0.7066072\n",
      "adversarial loss 0.6748896\n",
      "discriminator loss 0.712381\n",
      "adversarial loss 0.78720677\n",
      "discriminator loss 0.6993965\n",
      "adversarial loss 0.7309082\n",
      "discriminator loss 0.69580716\n",
      "adversarial loss 0.74253476\n",
      "discriminator loss 0.6953584\n",
      "adversarial loss 0.7687174\n",
      "discriminator loss 0.6915234\n",
      "adversarial loss 0.74754936\n",
      "discriminator loss 0.68943083\n",
      "adversarial loss 0.764654\n",
      "discriminator loss 0.6964219\n",
      "adversarial loss 0.7693487\n",
      "discriminator loss 0.7052382\n",
      "adversarial loss 0.7695377\n",
      "discriminator loss 0.68648714\n",
      "adversarial loss 0.8261777\n",
      "discriminator loss 0.70541686\n",
      "adversarial loss 0.71943456\n",
      "discriminator loss 0.6847758\n",
      "adversarial loss 0.7280377\n",
      "discriminator loss 0.7031552\n",
      "adversarial loss 0.73028755\n",
      "discriminator loss 0.6821357\n",
      "adversarial loss 1.0340722\n",
      "discriminator loss 0.7017747\n",
      "adversarial loss 0.7749983\n",
      "discriminator loss 0.84376776\n",
      "adversarial loss 0.86002845\n",
      "discriminator loss 0.6754239\n",
      "adversarial loss 0.8172635\n",
      "discriminator loss 0.7175081\n",
      "adversarial loss 0.7310359\n",
      "discriminator loss 0.6786727\n",
      "adversarial loss 0.8345367\n",
      "discriminator loss 0.67793036\n",
      "adversarial loss 0.76337755\n",
      "discriminator loss 0.73300564\n",
      "adversarial loss 5.4290843\n",
      "discriminator loss 0.6770715\n",
      "adversarial loss 0.8692204\n",
      "discriminator loss 0.75840104\n",
      "adversarial loss 0.9173168\n",
      "discriminator loss 0.73228776\n",
      "adversarial loss 0.90449333\n",
      "discriminator loss 0.667422\n",
      "adversarial loss 0.77888745\n",
      "discriminator loss 0.6772661\n",
      "adversarial loss 0.8605604\n",
      "discriminator loss 0.673677\n",
      "adversarial loss 0.70633096\n",
      "discriminator loss 0.7168874\n",
      "adversarial loss 0.8802217\n",
      "discriminator loss 0.70384604\n",
      "adversarial loss 0.7695827\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5f2bcb2800b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m#Обучение генератора (через модель gan, то есть с замороженным дискриминатором)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0ma_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_latent_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmisleading_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = 'GAN (8.5)/'\n",
    "\n",
    "start = 0\n",
    "for step in tqdm_notebook(range(iterations)):\n",
    "    #Выбор случайных точек из скрытого пространства\n",
    "    random_latent_vectors = np.random.normal(size = (batch_size, latent_dim))\n",
    "    #Декодируем точки в поддельное изображение\n",
    "    generated_images = generator.predict(random_latent_vectors) \n",
    "    \n",
    "    #Объединяем подделки с настоящими изображениями\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start:stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    \n",
    "    #Сборка меток изображений\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape) #Добавление случайного шума в метки\n",
    "    \n",
    "    #Обучение дискриминатора\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    #Выбор случайных точек из скрытого пространства\n",
    "    random_latent_vectors = np.random.normal(size = (batch_size, latent_dim))\n",
    "    \n",
    "    #Сборка меток изображений, которые всегда говорят \"настоящее\" (это ложь)\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "    \n",
    "    #Обучение генератора (через модель gan, то есть с замороженным дискриминатором)\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "    #Сохраняем изображения и текущую версию модели\n",
    "    if step % 100 == 0: \n",
    "        gan.save_weights(os.path.join(save_dir,'gan.h5'))\n",
    "        print('discriminator loss', d_loss)\n",
    "        print('adversarial loss', a_loss)\n",
    "        \n",
    "        img = image.array_to_img(generated_images[0] * 255., scale = False)\n",
    "        imwrite(os.path.join(save_dir, 'generated_' + str(step) + '.png'), img)\n",
    "        \n",
    "        img = image.array_to_img(real_images[0] * 255., scale = False)\n",
    "        imwrite(os.path.join(save_dir, 'real_' + str(step) + '.png'), img)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
